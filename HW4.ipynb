{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wiickz/MAT421/blob/main/HW4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFZwJmfPold6"
      },
      "source": [
        "## Section 19.1: Root Finding Problem Statement\n",
        "\n",
        "The goal of this chapter is to explore various methods for finding roots/zeros of a function. While the roots of some functions can easily be determined algebraically, others may be difficult to compute by hand:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0O8mQQ3old8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy import optimize\n",
        "\n",
        "f = lambda x: np.cos(x) - x # example function - algebra does not help us well here\n",
        "x = np.linspace(-2, 2, 100)\n",
        "\n",
        "r = optimize.fsolve(f, 0.5) # finds the root of f near 0.5\n",
        "print(r)\n",
        "\n",
        "plt.plot(x, f(x), 'b')\n",
        "plt.plot(x, np.zeros_like(x), 'r--')\n",
        "plt.plot(r, 0, 'ro')\n",
        "plt.text(r[0], 0, '(%.4f, 0)' % r[0], verticalalignment='bottom')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yktwtDPuold9"
      },
      "source": [
        "## Section 19.2: Tolerance\n",
        "\n",
        "Root-finding programs often do so via numerical computations that converge towards the nearest zero over some number of iterations. Since this iterative method only approaches (and never truly reaches) the zero point, these functions usually have a built-in tolerance level at which the iteration stops and the approximate zero is returned:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cf1Fl_bCold9"
      },
      "outputs": [],
      "source": [
        "#Code until end of fixedpt() function is excerpt of own work from MAT 423 - Numerical Analysis I\n",
        "#Fixed point iteration method to find a root of a function\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def fixedpt(func, x0, k=50, tol=1e-6):\n",
        "    '''Fixed point iteration'''\n",
        "\n",
        "    x = x0\n",
        "    x_list = [x]\n",
        "\n",
        "    for i in range(k):\n",
        "        x = func(x)\n",
        "        x_list.append(x)\n",
        "\n",
        "        if abs(x - x_list[-2]) < tol:\n",
        "            n = i\n",
        "            break\n",
        "\n",
        "    return x_list, n\n",
        "\n",
        "#Fixed point iteration uses the original function f(x) to create a new function g(x) = x - f(x), which is then used to find the root of f(x)\n",
        "\n",
        "f_x = lambda x: 0.5 - x + 0.2*np.sin(x) # assumed to be = 0\n",
        "g_x = lambda x: 0.5 + 0.2*np.sin(x) # g(x) = x - f(x) = 0 -> x = g(x)\n",
        "\n",
        "x0 = 0.5 # initial guess\n",
        "tol = 1e-6 # tolerance - try changing this to see how it affects the number of iterations\n",
        "\n",
        "x_list, n = fixedpt(g_x, x0, tol=tol)\n",
        "\n",
        "print('Root:', x_list[-1])\n",
        "print('Number of iterations:', n)\n",
        "print('Convergence:')\n",
        "for i, x in enumerate(x_list):\n",
        "    print('x_%d = %.7f' % (i, x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWRSjLQsold9"
      },
      "source": [
        "The solution found above is accurate to the sixth decimal place, and the convergence list shows how the solution approached this tolerance. For most purposes, six digits of accuracy is more than enough, which is why this particular tolerance was chosen - anything more would require more iterations (and thus computation time) for a likely unneeded level of accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AVIuBncold9"
      },
      "source": [
        "## Section 19.3: Bisection Method\n",
        "\n",
        "The bisection method works much in the same way as a binary search - given a function and two values of x, the algorithm assumes that the function is continuous, that one of the x values returns a value less than zero when input to the function, and that the other returns a value greater than zero. With these assumptions, the Intermediate Value Theorem kicks into play - somewhere between these two values, another value *must* exist where f(x) = 0. The algorithm now looks at the midpoint, checks whether it returns a value greater or less than zero, then sets the midpoint as one of the new bounds depending on what it finds. This algorithm repeats until the specified tolerance is reached:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvgZlHsyold9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Yes, I also did this in 423. The function here is modified from that work, however -\n",
        "# for some reason, my 423 work assumed it would always converge.\n",
        "# I've added a maximum number of iterations for this version.\n",
        "\n",
        "def bisection(func, a, b, k=50, tol=1e-6):\n",
        "    '''Bisection algorithm'''\n",
        "    m = (a + b) / 2\n",
        "    for i in range(k):\n",
        "        if abs(func(m)) < tol:\n",
        "            n = i\n",
        "            break\n",
        "\n",
        "        if func(a) * func(m) <= 0:\n",
        "            b = m\n",
        "        else:\n",
        "            a = m\n",
        "\n",
        "        m = (a + b) / 2\n",
        "\n",
        "    return m, n\n",
        "\n",
        "\n",
        "f_x = lambda x: x**2 - x**3 + (x+1)**2 - 2 # function\n",
        "\n",
        "# guessing interval\n",
        "a = -3\n",
        "b = 2\n",
        "# note there are multiple zeros within this interval - more on this later\n",
        "\n",
        "tol = 1e-6\n",
        "\n",
        "root, n = bisection(f_x, a, b, tol=tol)\n",
        "\n",
        "print('Root:', root)\n",
        "print('Number of iterations:', n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrSjwMH-old-"
      },
      "source": [
        "It is also worth noting that this method has a form of bias. Depending on the implementation, when multiple zeros exist on the interval, the algorithm will always converge to a particular zero. In the above implementation, the algorithm will always return a zero to the left of the midpoint - usually the leftmost zero, but this is not always the case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znxsjp1gold-"
      },
      "source": [
        "## Section 19.4: Newton-Raphson Method\n",
        "\n",
        "This method for finding roots does away with the Intermediate Value Theorem and boundary guesses, making use of a much simpler method where the algorithm assumes calculus has been invented and instead uses the input function, its derivative and a single guess. The Newton-Raphson method is still iterative, refining its guess over time by plugging that guess into both the function and its derivative:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCdNYKeYold_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def newton(func, dfunc, x0, k=50, tol=1e-6):\n",
        "    '''Newton's method'''\n",
        "    x = x0\n",
        "\n",
        "    for i in range(k):\n",
        "        x = x - func(x) / dfunc(x)\n",
        "\n",
        "        if abs(func(x)) < tol:\n",
        "            n = i\n",
        "            break\n",
        "\n",
        "    return x, n\n",
        "\n",
        "f_x = lambda x: 4*np.sin(x) - np.exp(x)\n",
        "d_f_x = lambda x: 4*np.cos(x) - np.exp(x)\n",
        "\n",
        "x0 = 0.5 # guess\n",
        "\n",
        "root, n = newton(f_x, d_f_x, x0)\n",
        "\n",
        "print('Root:', root)\n",
        "print('Number of iterations:', n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWaJdlizold_"
      },
      "source": [
        "Since this algorithm uses a single guess instead of a boundary, it will typically simply converge to the nearest zero rather than work under a specific bias. Regardless of the zero it does find, it usually does so in significantly fewer iterations."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}