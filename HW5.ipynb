{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wiickz/MAT421/blob/main/HW5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hH1XUd2fPie"
      },
      "source": [
        "## Section 1.1: Introduction to Linear Algebra\n",
        "\n",
        "The unique approach to solving mathematical problems often found in linear algebra extends well to the fields of numerical analysis and data science. Handling large quantities of data using standard algebraic techniques would be time-consuming, even with the help of computers. However, by applying concepts of linear algebra, even larger systems can be handled quite well:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0KFoeMIfPif"
      },
      "outputs": [],
      "source": [
        "### Excerpt from own work in MAT 423: Numerical Analysis I\n",
        "### LDL^T factorization to solve a system of linear equations represented as a matrix equation Ax = b\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def p4(A, b):\n",
        "    '''Solve a linear system Ax = b using LDL^T factorization'''\n",
        "    n = A.shape[0]\n",
        "    L = np.zeros((n, n))\n",
        "    D = np.zeros(n)\n",
        "    for i in range(n):\n",
        "        s = 0\n",
        "        for k in range(i):\n",
        "            s += D[k] * L[i, k] ** 2\n",
        "        D[i] = A[i, i] - s\n",
        "        L[i, i] = 1\n",
        "        for j in range(i+1, n):\n",
        "            s = 0\n",
        "            for k in range(i):\n",
        "                s += D[k] * L[i, k] * L[j, k]\n",
        "            L[j, i] = (A[j, i] - s) / D[i]\n",
        "    print('L =', L)\n",
        "    print('D =', D)\n",
        "    y = np.zeros(n)\n",
        "    y[0] = b[0]\n",
        "    for i in range(1, n):\n",
        "        s = 0\n",
        "        for k in range(i):\n",
        "            s += L[i, k] * y[k]\n",
        "        y[i] = b[i] - s\n",
        "    z = np.zeros(n)\n",
        "    for i in range(n):\n",
        "        z[i] = y[i] / D[i]\n",
        "    x = np.zeros(n)\n",
        "    x[n-1] = z[n-1]\n",
        "    for i in range(n-2, -1, -1):\n",
        "        s = 0\n",
        "        for k in range(i+1, n):\n",
        "            s += L[k, i] * x[k]\n",
        "        x[i] = z[i] - s\n",
        "\n",
        "    return x\n",
        "\n",
        "# sample systems\n",
        "A1 = np.array([[4, 1, 1, 1], [1, 3, -1, 1], [1, -1, 2, 0], [1, 1, 0, 2]])\n",
        "b1 = np.array([0.65, 0.05, 0, 0.5])\n",
        "x1 = p4(A1, b1)\n",
        "print('x1 =', x1)\n",
        "\n",
        "A2 = np.array([[6, 2, 1, -1], [2, 4, 1, 0], [1, 1, 4, -1], [-1, 0, -1, 3]])\n",
        "b2 = np.array([0, 7, -1, -2])\n",
        "x2 = p4(A2, b2)\n",
        "print('x2 =', x2)\n",
        "\n",
        "# a bit rough on the edges in terms of output presentation, but it does work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26OYekAyfPig"
      },
      "source": [
        "## Section 1.2: Elements of Linear Algebra\n",
        "\n",
        "We're getting a little ahead of ourselves here. Let's start with some of the basic concepts:\n",
        "\n",
        "### Linear Spaces (and the basis)\n",
        "\n",
        "A linear space can be defined as a set of vectors whose elements can be multiplied by scalars and/or added together to create a result vector that also exists within the same set. Linear spaces have linear subspaces that exist under similar conditions: as a subset of a linear space, all multiplication/addition operations on the comprising vectors result in vectors that exist within the subset (and thus the set).\n",
        "\n",
        "As an example, suppose we have a linear space consisting of vectors [x, y, z]. Multiplying one of these vectors, or adding two (or three) of them together, results in a value that still depends entirely on the basis vectors (e.g. 2y or x+z). A subspace can be created consisting of only one or two of the basis vectors (e.g. [x, z]) that still follows the same rules (with multiplication or addition operations still creating results such as 4z+x).\n",
        "\n",
        "### Linear Independence\n",
        "\n",
        "Suppose we have such a linear space with a set of vectors like the one above. Sometimes, one vector can be expressed in terms of one or more of the other vectors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QidWoNs3fPig"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.array([1, 2, 3, 4])\n",
        "y = np.array([2, 4, 6, 8])\n",
        "\n",
        "print(\"x: \", x)\n",
        "print(\"y: \", y)\n",
        "print(\"2x: \", 2*x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fg_3NRslfPih"
      },
      "source": [
        "If this is the case, then the vectors are linearly dependent - but if not, then we can say the vectors are linearly independent. A scalar value of zero is an exception here, as any vector, no matter its magnitude, multiplied by zero will create a zero vector.\n",
        "\n",
        "### Orthogonality\n",
        "\n",
        "Orthogonality, grossly simplified, is a measure of vector perpendicularity. If the inner product of two vectors is zero, then they are considered to be orthogonal. However, if you have a list of vectors, and (a) for each combination of two vectors, their inner product is zero, and (b) the norm of each vector is equal to 1, then the list is said to be orthonormal:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhyprTiNfPih"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.array([1, 0, 0])\n",
        "y = np.array([0, 1, 0])\n",
        "z = np.array([0, 0, 1])\n",
        "\n",
        "print(\"x: \", x)\n",
        "print(\"y: \", y)\n",
        "print(\"z: \", z)\n",
        "print(\"<x, y>: \", np.dot(x, y))\n",
        "print(\"<y, z>: \", np.dot(y, z))\n",
        "print(\"<z, x>: \", np.dot(z, x))\n",
        "print(\"||x||: \", np.linalg.norm(x))\n",
        "print(\"||y||: \", np.linalg.norm(y))\n",
        "print(\"||z||: \", np.linalg.norm(z))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9a_UhACfPih"
      },
      "source": [
        "### The Gram-Schmidt Process\n",
        "\n",
        "If we have a set of vectors that are linearly independent, then that set has an orthonormal basis. This basis can be found for any set using the Gram-Schmidt process:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCKgRsfLfPih"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def proj(u, v):\n",
        "    return np.dot(u, v) / np.dot(u, u) * u\n",
        "\n",
        "def gram_schmidt(A):\n",
        "    U = np.zeros(A.shape)\n",
        "    E = np.zeros(A.shape)\n",
        "    U[0] = A[0]\n",
        "    E[0] = U[0] / np.linalg.norm(U[0])\n",
        "    for i in range(1, A.shape[0]):\n",
        "        U[i] = A[i]\n",
        "        for j in range(i):\n",
        "            U[i] -= proj(E[j], A[i])\n",
        "        E[i] = U[i] / np.linalg.norm(U[i])\n",
        "\n",
        "    return U, E\n",
        "\n",
        "A = np.array([[1, 0, 0], [1, 1, 0], [1, 1, 1]])\n",
        "U, E = gram_schmidt(A)\n",
        "print(\"A:\\n\", A)\n",
        "print(\"U:\\n\", U)\n",
        "print(\"E:\\n\", E)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dk_12PDFfPih"
      },
      "source": [
        "The Gram-Schmidt process takes in a set of linearly independent vectors A and returns a set of orthogonal vectors U and their corresponding orthonormal set E. This above example is quite simple, as the orthogonal vectors in U are already normalized, but for larger/more complex sets of vectors, U and E are likely to differ.\n",
        "\n",
        "### Eigenvalues and Eigenvectors\n",
        "\n",
        "In certain cases, a square matrix of values A may have corresponding eigenvalues 位 and eigenvectors *x* such that A*x* = 位*x*. A simple method for determining the eigenvalues of any A algebraically is to find all 位 that satisfy the equation det(A-位I) = 0 (where I is the identity matrix of same size as A). However, since eigenvalues and eigenvectors are very common in applied linear algebra, Python functions do exist to determine the eigenvalues/vectors for you:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLV2Gh8ifPij"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "#matrix with real eigenvalues\n",
        "A = np.array([[1, 2], [2, 1]])\n",
        "\n",
        "print(\"A:\\n\", A)\n",
        "print(\"Eigenvalues:\\n\", np.linalg.eigvals(A))\n",
        "print(\"Eigenvectors:\\n\", np.linalg.eig(A).eigenvectors)\n",
        "\n",
        "#matrix with complex eigenvalues\n",
        "B = np.array([[0, -1], [1, 0]])\n",
        "\n",
        "print(\"B:\\n\", B)\n",
        "print(\"Eigenvalues:\\n\", np.linalg.eigvals(B))\n",
        "print(\"Eigenvectors:\\n\", np.linalg.eig(B).eigenvectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9201hO3fPij"
      },
      "source": [
        "## Section 1.3: Linear Regression\n",
        "\n",
        "Linear regression attempts to fit data using a function, similar to linear interpolation but instead with the goal to simply model existing data as best as possible, with interpolation as more of an afterthought. Given a set of independent vectors *x1, x2, ..., xn* and a response to the vectors *y*, the goal is to find coeffecients *尾1, 尾2, ..., 尾n* that minimize the difference between the true values and a prediction model. This is best framed as a least-squares problem searching for *min(尾) ||y-A尾||^2* and can be solved with a QR decomposition, where A is decomposed into two matrices Q (where Q * Q^T = I) and R (an upper triangular matrix) such that A = QR:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SzTIaAhfPij"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def proj(u, v):\n",
        "    return np.dot(u, v) / np.dot(u, u) * u\n",
        "\n",
        "def gram_schmidt(A):\n",
        "    U = np.zeros(A.shape)\n",
        "    E = np.zeros(A.shape)\n",
        "    U[0] = A[0]\n",
        "    E[0] = U[0] / np.linalg.norm(U[0])\n",
        "    for i in range(1, A.shape[0]):\n",
        "        U[i] = A[i]\n",
        "        for j in range(i):\n",
        "            U[i] -= proj(E[j], A[i])\n",
        "        E[i] = U[i] / np.linalg.norm(U[i])\n",
        "\n",
        "    return U, E\n",
        "\n",
        "def qr(A):\n",
        "    U, E = gram_schmidt(A)\n",
        "    Q = E.T\n",
        "    R = np.zeros((A.shape[1], A.shape[1]))\n",
        "    for i in range(A.shape[1]):\n",
        "        for j in range(i, A.shape[1]):\n",
        "            R[i, j] = np.dot(E[i], A[j])\n",
        "\n",
        "    return Q, R\n",
        "\n",
        "def linreg(X, Y):\n",
        "    Q, R = qr(X)\n",
        "    QTY = np.dot(Q.T, Y)\n",
        "    尾 = np.linalg.solve(R, QTY)\n",
        "\n",
        "    return 尾\n",
        "\n",
        "X = np.array([[4, 1, 3], [2, 1, 2], [2, 3, 1]])\n",
        "Y = np.array([5, 3, 7])\n",
        "尾 = linreg(X, Y)\n",
        "print(\"尾: \", 尾)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}