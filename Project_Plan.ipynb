{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wiickz/MAT421/blob/main/Project_Plan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2TXxH-24E_8"
      },
      "source": [
        "# Generation of Interpolative and Extrapolative Numerical Weather Prediction Models\n",
        "\n",
        "### Introduction\n",
        "Billions of people rely on weather forecasts each day to get a sense of upcoming outdoor conditions and make plans according to those conditions. However, due to limitations on accurately predicting upcoming weather, most forecasting apps focus solely on the upcoming 2-4 weeks of predicted weather; additionally, many of these apps do not make historical data readily available. The goal of this project is to create a proof-of-concept Python script to address both of these limitations by generating models based on historical data that can be later used to quickly look up previous weather data as well as generate semi-accurate weather predictions for future dates with no limit.\n",
        "\n",
        "### Related Work\n",
        "This method of weather modeling is not an entirely novel concept; according to Ryuji Kimura's overview paper [*Numerical weather prediction*](https://doi.org/10.1016/S0167-6105(02)00261-1), the idea of using computers to model and predict weather patterns has been theorized as early as 1922 but was not viable due to a lack of both meterological data and computational ability. This has since drastically changed and nowadays most major weather stations report forecasts based on simulation data. These simulations are much more complex than the planned method for this project, but are much more accurate in predicting immediate forecasts. Extended forecasting is still difficult due to the massive number of potentially fluctuating conditions present on Earth; Kimura reports that the method for acquiring 1-month forecast data in Japan involves compiling statistics from 26 different simulations, each having slight variation in its initial conditions. The method for this project will take a different approach in data usage (further detailed in the next section) that relies on bulk historical data available via the [Open-meteo API](https://open-meteo.com/), capable of providing temperature and other weather data dating as far back as 1940 for some locations.\n",
        "\n",
        "### Proposed Methodology, Experiment Setups, and Expected Results\n",
        "The project will be implemented in the form of a script or set of scripts written in Python that will, for a given location:\n",
        "* gather a sufficiently large collection of historical forecast data,\n",
        "* create a model based on that data to quickly generate an interpolated forecast estimate for any date within the historical data range,\n",
        "* expand that model based on observed patterns to attempt to extrapolate and predict future weather patterns,\n",
        "* save the model for later re-use to avoid having to fetch the entire data set every time weather for a previously modeled location is requested.\n",
        "\n",
        "The project will be implemented in a 'one-size-fits-all' approach, where the same code can be used to generate/utilize a model for any location input by the user.\n",
        "\n",
        "As mentioned in the previous section, the Open-meteo API/database will be the primary source of data gathered for this project. Open-meteo provides a custom Python package `openmeteo-requests` to assist with this data gathering, and theoretically only one request should be required per location; however, not every location will have recorded weather data going all the way back to 1940, and thus the start date may need to be adjusted per location by the script. The number of API calls is also limited by Open-meteo to 10,000 per day, and larger requests are considered equivalent to multiple calls due to the sheer amount of data being returned (as Open-meteo's 90-terabyte dataset contains reported values down to the hour) - this is unlikely to be an issue for the purposes of this project, as it is not anticipated that the amount of data requested over the course of the entire project will exceed the daily limit.\n",
        "\n",
        "The models based on this data are planned to be created using interpolation functions, with one function generated per year of data. Since man-made alterations to Earth's ecosystem have resulted in average temperatures increasing every year, this should be the better approach to the problem, as it allows for that temperature increase to be considered when extrapolating beyond available data. It should be noted that this approach will likely only work well on future extrapolations, since these aforementioned man-made influences have only taken hold in the more recent decades - this is an acceptable compromise, as extrapolating into the past has less use than extrapolating into the future."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}